# Nothing to Add - å®Œæ•´å¼€å‘è®¡åˆ’

> **ä»æ•°æ®æ¸…æ´—åˆ°ä¸Šçº¿çš„å®Œæ•´è·¯çº¿å›¾**
>
> 6å‘¨æ—¶é—´ï¼Œæ¯å¤©2-3å°æ—¶ï¼Œæ‰“é€ ä¸“ä¸šçº§å‰åç«¯åˆ†ç¦»AIé¡¹ç›®

---

## ğŸ—ºï¸ æ€»ä½“è§„åˆ’

**åŒè¯­æ”¯æŒ** ğŸŒï¼šæœ¬é¡¹ç›®æ”¯æŒä¸­è‹±åŒè¯­ï¼Œä»¥ä¸‹å„é˜¶æ®µéƒ½ä¼šåŒ…å«åŒè¯­ç›¸å…³çš„ä»»åŠ¡

```
ç¬¬1å‘¨ï¼šæ•°æ®æ”¶é›†ä¸æ¸…æ´—ï¼ˆåŒè¯­æ•°æ®ï¼‰
â”œâ”€ æ”¶é›†ä¸­è‹±æ–‡æ•°æ®ï¼ˆè‚¡ä¸œä¿¡ã€ä¹¦ç±ï¼‰
â”œâ”€ æ ‡æ³¨è¯­è¨€æ ‡ç­¾ï¼ˆzh/enï¼‰
â”œâ”€ æå–æ–‡å­—å†…å®¹
â”œâ”€ æ¸…æ´—å’Œæ ¼å¼åŒ–
â””â”€ å‡†å¤‡åŒè¯­è®­ç»ƒæ•°æ®

ç¬¬2å‘¨ï¼šRAGç³»ç»Ÿæ­å»ºï¼ˆæ”¯æŒåŒè¯­æ£€ç´¢ï¼‰
â”œâ”€ æ–‡æ¡£åˆ‡åˆ†ï¼ˆä¿ç•™è¯­è¨€æ ‡ç­¾ï¼‰
â”œâ”€ å‘é‡åŒ–ï¼ˆä½¿ç”¨æ”¯æŒä¸­è‹±æ–‡çš„æ¨¡å‹ï¼‰
â”œâ”€ å‘é‡æ•°æ®åº“
â””â”€ æ£€ç´¢åŠŸèƒ½ï¼ˆä¸­è‹±æ–‡æ··åˆæ£€ç´¢ï¼‰

ç¬¬3å‘¨ï¼šåç«¯APIå¼€å‘ï¼ˆåŒè¯­æ”¯æŒï¼‰
â”œâ”€ FastAPIæ¡†æ¶
â”œâ”€ è¯­è¨€æ£€æµ‹æ¨¡å—
â”œâ”€ åŒè¯­Promptå·¥ç¨‹
â”œâ”€ LLMé›†æˆ
â””â”€ APIæ¥å£ï¼ˆè‡ªåŠ¨è¯­è¨€åˆ‡æ¢ï¼‰

ç¬¬4å‘¨ï¼šåç«¯éƒ¨ç½²
â”œâ”€ åŠŸèƒ½å®Œå–„
â”œâ”€ åŒè¯­åŠŸèƒ½æµ‹è¯•
â”œâ”€ æµ‹è¯•
â””â”€ Railwayéƒ¨ç½²

ç¬¬5å‘¨ï¼šReactå‰ç«¯å¼€å‘ï¼ˆåŒè¯­UIï¼‰
â”œâ”€ ç»„ä»¶å¼€å‘ï¼ˆè¯­è¨€åˆ‡æ¢ï¼‰
â”œâ”€ é¡µé¢å¸ƒå±€
â”œâ”€ APIé›†æˆ
â””â”€ æ ·å¼ä¼˜åŒ–

ç¬¬6å‘¨ï¼šå‰ç«¯éƒ¨ç½²ä¸ä¸Šçº¿
â”œâ”€ Verceléƒ¨ç½²
â”œâ”€ å®Œæ•´åŒè¯­æµ‹è¯•
â”œâ”€ GitHubå¼€æº
â””â”€ æ¨å¹¿
```

---

## ğŸ“‹ ç¬¬1å‘¨ï¼šæ•°æ®æ”¶é›†ä¸æ¸…æ´—

**ç›®æ ‡**ï¼šå‡†å¤‡å¥½æ‰€æœ‰è®­ç»ƒæ•°æ®

---

### Day 1: é¡¹ç›®åˆå§‹åŒ–

#### ğŸ“ åˆ›å»ºé¡¹ç›®ç»“æ„

```bash
# åˆ›å»ºé¡¹ç›®æ ¹ç›®å½•
mkdir -p nothing-to-add-project

# è¿›å…¥ç›®å½•
cd nothing-to-add-project

# åˆ›å»ºåç«¯ç›®å½•
mkdir nothing-to-add-backend
cd nothing-to-add-backend

# åˆ›å»ºPythonè™šæ‹Ÿç¯å¢ƒ
python -m venv venv

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
# Windows:
venv\Scripts\activate
# Mac/Linux:
source venv/bin/activate

# å®‰è£…åŸºç¡€ä¾èµ–
pip install requests beautifulsoup4 pypdf python-dotenv

# åˆ›å»ºé¡¹ç›®ç»“æ„
mkdir -p app/{api,services,models,core}
mkdir -p data/{raw,processed,chroma}
mkdir -p scripts

touch app/__init__.py
touch app/main.py
touch requirements.txt
touch .env.example
touch .gitignore

# è¿”å›æ ¹ç›®å½•
cd ..
```

**âœ… æ£€æŸ¥ç‚¹**ï¼š
```
â–¡ è™šæ‹Ÿç¯å¢ƒåˆ›å»ºæˆåŠŸ
â–¡ èƒ½æ¿€æ´»å’Œé€€å‡ºè™šæ‹Ÿç¯å¢ƒ
â–¡ åŸºç¡€åŒ…å®‰è£…æˆåŠŸ
â–¡ é¡¹ç›®ç»“æ„åˆ›å»ºå®Œæˆ
```

---

### Day 2: åˆ›å»ºå‰ç«¯é¡¹ç›®

```bash
# ä½¿ç”¨Viteåˆ›å»ºReacté¡¹ç›®
npm create vite@latest nothing-to-add-frontend -- --template react-ts

# è¿›å…¥å‰ç«¯ç›®å½•
cd nothing-to-add-frontend

# å®‰è£…ä¾èµ–
npm install

# å®‰è£…é¢å¤–ä¾èµ–
npm install axios lucide-react
npm install -D tailwindcss postcss autoprefixer

# åˆå§‹åŒ–TailwindCSS
npx tailwindcss init -p

# é…ç½®Tailwind
# tailwind.config.js:
export default {
  content: [
    "./index.html",
    "./src/**/*.{js,ts,jsx,tsx}",
  ],
  theme: {
    extend: {},
  },
  plugins: [],
}

# src/index.css æ·»åŠ ï¼š
@tailwind base;
@tailwind components;
@tailwind utilities;

# æµ‹è¯•è¿è¡Œ
npm run dev

# âœ… æ£€æŸ¥ç‚¹ï¼šè®¿é—® http://localhost:5173 èƒ½çœ‹åˆ°Reactæ¬¢è¿é¡µ
```

**âœ… æ£€æŸ¥ç‚¹**ï¼š
```
â–¡ Reacté¡¹ç›®åˆ›å»ºæˆåŠŸ
â–¡ TailwindCSSé…ç½®å®Œæˆ
â–¡ èƒ½å¯åŠ¨å¼€å‘æœåŠ¡å™¨
â–¡ é¡µé¢æ­£å¸¸æ˜¾ç¤º
```

---

### Day 3-4: æ•°æ®æ”¶é›† ğŸŒï¼ˆåŒè¯­æ•°æ®ï¼‰

#### ä¸‹è½½å·´è²ç‰¹è‡´è‚¡ä¸œä¿¡ï¼ˆå·²æœ‰åŒè¯­ç‰ˆæœ¬ï¼‰

**âœ… ç‰¹æ®Šæƒ…å†µï¼šå·²æœ‰åŒè¯­ç‰ˆæœ¬**

æœ¬é¡¹ç›®å·²ç»æ‹¥æœ‰å®Œæ•´çš„ä¸­è‹±å¯¹ç…§è‚¡ä¸œä¿¡ï¼ˆ1965-2024ï¼‰ï¼Œæ¥æºï¼š
- GitHub: https://github.com/pzponge/Yestoday/tree/main/Warren_Buffett/Berkshire_Hathaway_Letters
- æ ¼å¼ï¼šMarkdown
- ç¿»è¯‘ï¼šé«˜è´¨é‡ä¸­è‹±å¯¹ç…§

**ç›´æ¥ä½¿ç”¨**ï¼š
```bash
# å¤åˆ¶åˆ°é¡¹ç›®
cp -r "Yestoday/Warren_Buffett/Berkshire_Hathaway_Letters" \
      "nothing-to-add-backend/data/processed/shareholder_letters/"

# éªŒè¯
ls data/processed/shareholder_letters/
# åº”è¯¥çœ‹åˆ°ï¼š1965_Letter_to_Berkshire_Shareholders.md ... 2024_Letter_to_Berkshire_Shareholders.md
```

**æ•°æ®æ ¼å¼**ï¼š
```markdown
# BERKSHIRE HATHAWAY INC.
To the Shareholders of Berkshire Hathaway Inc.:
è‡´ä¼¯å…‹å¸Œå°”Â·å“ˆæ’’éŸ¦å…¬å¸è‚¡ä¸œä»¬ï¼š

This letter comes to you as part of Berkshire's annual report.
è¿™å°ä¿¡æ˜¯ä¼¯å…‹å¸Œå°”å¹´åº¦æŠ¥å‘Šçš„ä¸€éƒ¨åˆ†ã€‚
...
```

**æ–¹æ³•1ï¼šæ‰‹åŠ¨ä¸‹è½½**

```bash
# åˆ›å»ºæ•°æ®æ–‡ä»¶å¤¹
cd nothing-to-add-backend/data/raw/letters

# è®¿é—®è¿™äº›é“¾æ¥å¹¶æ‰‹åŠ¨ä¸‹è½½ï¼š
# https://www.berkshirehathaway.com/letters/2024ltr.pdf
# https://www.berkshirehathaway.com/letters/2023ltr.pdf
# https://www.berkshirehathaway.com/letters/2022ltr.pdf
# https://www.berkshirehathaway.com/letters/2021ltr.pdf
# https://www.berkshirehathaway.com/letters/2020ltr.pdf
```

**æ–¹æ³•2ï¼šä½¿ç”¨è„šæœ¬ä¸‹è½½**

```python
# scripts/download_letters.py
import requests
import os

def download_letter(year):
    """ä¸‹è½½æŸå¹´çš„è‚¡ä¸œä¿¡"""
    url = f"https://www.berkshirehathaway.com/letters/{year}ltr.pdf"

    try:
        response = requests.get(url)
        if response.status_code == 200:
            filename = f"data/raw/letters/{year}_letter.pdf"
            os.makedirs(os.path.dirname(filename), exist_ok=True)

            with open(filename, 'wb') as f:
                f.write(response.content)

            print(f"âœ… ä¸‹è½½å®Œæˆï¼š{year}å¹´è‚¡ä¸œä¿¡")
        else:
            print(f"âŒ å¤±è´¥ï¼š{year}å¹´")
    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼š{year}å¹´ - {e}")

# ä¸‹è½½æœ€è¿‘5å¹´çš„ä¿¡
for year in range(2019, 2025):
    download_letter(year)

# ä¸‹è½½æ—©æœŸä¿¡ä»¶ï¼ˆå¯é€‰ï¼‰
for year in [2015, 2010, 2005, 2000, 1995]:
    download_letter(year)
```

**è¿è¡Œ**ï¼š
```bash
cd nothing-to-add-backend
python scripts/download_letters.py
```

---

#### æ”¶é›†è‚¡ä¸œå¤§ä¼šè®°å½•

```python
# scripts/download_meetings.py
"""
ä»CNBCæˆ–Rev.comè·å–è‚¡ä¸œå¤§ä¼šæ–‡å­—è®°å½•

è¿™äº›ç½‘ç«™æœ‰å®Œæ•´çš„è‚¡ä¸œå¤§ä¼šæ–‡å­—è®°å½•
"""

# æ‰‹åŠ¨è®¿é—®å¹¶ä¿å­˜ï¼š
# CNBC: https://www.cnbc.com/berkshire-hathaway-shareholder-meeting/
# Rev.com: æœç´¢ "Berkshire Hathaway annual meeting transcript"

# æˆ–è€…æœç´¢ï¼š
# "Berkshire Hathaway 2024 annual meeting transcript pdf"
# "Berkshire Hathaway 2023 annual meeting transcript pdf"

# ä¿å­˜åˆ°ï¼šdata/raw/meetings/
```

---

#### æ”¶é›†æ¼”è®²å’Œé‡‡è®¿

```python
# æ”¶é›†èµ„æºæ¸…å•
resources = {
    "books": [
        "ã€Šç©·æŸ¥ç†å®å…¸ã€‹",  # é‡ç‚¹æ”¶é›†
        "ã€Šå·´è²ç‰¹ä¼ ã€‹",
        "ã€Šèªæ˜çš„æŠ•èµ„è€…ã€‹",
    ],
    "speeches": [
        "å·´è²ç‰¹ä½›ç½—é‡Œè¾¾å¤§å­¦æ¼”è®²1998",
        "å·´è²ç‰¹ä¹”æ²»äºšç†å·¥å­¦é™¢æ¼”è®²",
        "èŠ’æ ¼åŠ å·ç†å·¥å­¦é™¢æ¼”è®²",
        "èŠ’æ ¼Daily Journalå¹´ä¼šæ¼”è®²",
    ],
    "interviews": [
        "CNBCé‡‡è®¿",
        "Charlie Rose Show",
        "CBS Sunday Morning",
    ]
}

# æç¤ºï¼šä½¿ç”¨YouTube + Whisperè½¬å½•è§†é¢‘
```

**âœ… æ£€æŸ¥ç‚¹**ï¼š
```
â–¡ è‡³å°‘5å°è‚¡ä¸œä¿¡PDF
â–¡ è‡³å°‘2æ¬¡è‚¡ä¸œå¤§ä¼šè®°å½•
â–¡ è‡³å°‘1ä¸ªæ¼”è®²æ–‡å­—ç¨¿
â–¡ æ•°æ®æ–‡ä»¶åˆ†ç±»å­˜æ”¾åœ¨data/raw/
```

---

### Day 5-6: æ•°æ®æ¸…æ´—

#### æå–PDFå†…å®¹

```python
# scripts/extract_pdf.py
import os
from pypdf import PdfReader

def extract_pdf_to_markdown(pdf_path, output_path):
    """æå–PDFå¹¶è½¬ä¸ºMarkdown"""
    print(f"å¤„ç†ï¼š{pdf_path}")

    try:
        reader = PdfReader(pdf_path)

        # æå–æ‰€æœ‰é¡µé¢
        content = []
        for i, page in enumerate(reader.pages, 1):
            text = page.extract_text()

            # æ¸…æ´—ï¼šå»é™¤å¤šä½™ç©ºæ ¼
            text = " ".join(text.split())

            content.append(f"## ç¬¬{i}é¡µ\n\n{text}\n")

        # ä¿å­˜ä¸ºMarkdown
        os.makedirs(os.path.dirname(output_path), exist_ok=True)

        with open(output_path, 'w', encoding='utf-8') as f:
            # å†™å…¥æ ‡é¢˜
            filename = os.path.basename(pdf_path)
            f.write(f"# {filename}\n\n")
            # å†™å…¥å†…å®¹
            f.write("\n".join(content))

        print(f"âœ… å·²ä¿å­˜ï¼š{output_path}")

    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥ï¼š{pdf_path} - {e}")

# æ‰¹é‡å¤„ç†
import glob

pdf_files = glob.glob("data/raw/letters/*.pdf")

for pdf_file in pdf_files:
    output_file = pdf_file.replace("raw/letters", "processed")
    output_file = output_file.replace(".pdf", ".md")

    extract_pdf_to_markdown(pdf_file, output_file)

print("\nâœ… æ‰¹é‡å¤„ç†å®Œæˆï¼")
```

**è¿è¡Œ**ï¼š
```bash
cd nothing-to-add-backend
python scripts/extract_pdf.py
```

---

#### é«˜çº§æ¸…æ´—

```python
# scripts/advanced_clean.py
import re
import glob

def advanced_clean_markdown(md_path):
    """é«˜çº§æ¸…æ´—Markdownæ–‡ä»¶"""

    with open(md_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # æ¸…æ´—æ­¥éª¤
    # 1. ç»Ÿä¸€æ¢è¡Œç¬¦
    content = content.replace('\r\n', '\n')

    # 2. å»é™¤å¤šä½™ç©ºè¡Œ
    content = re.sub(r'\n{3,}', '\n\n', content)

    # 3. å»é™¤é¡µç 
    content = re.sub(r'ç¬¬\d+é¡µ', '', content)

    # 4. ä¿®å¤ç‰¹æ®Šå­—ç¬¦
    content = content.replace('"', '"').replace('"', '"')
    content = content.replace(''', "'").replace(''', "'")

    # 5. å»é™¤é¡µçœ‰é¡µè„šï¼ˆå¦‚æœæœ‰è§„å¾‹ï¼‰
    # æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´

    # ä¿å­˜
    with open(md_path, 'w', encoding='utf-8') as f:
        f.write(content)

    print(f"âœ… æ¸…æ´—å®Œæˆï¼š{md_path}")

# æ‰¹é‡æ¸…æ´—
md_files = glob.glob("data/processed/*.md")

for md_file in md_files:
    advanced_clean_markdown(md_file)

print("\nâœ… é«˜çº§æ¸…æ´—å®Œæˆï¼")
```

---

#### æ•°æ®è´¨é‡æ£€æŸ¥

```python
# scripts/check_data_quality.py
import glob

def check_data_quality():
    """æ£€æŸ¥æ•°æ®è´¨é‡"""

    md_files = glob.glob("data/processed/*.md")

    print(f"ğŸ“Š æ•°æ®è´¨é‡æŠ¥å‘Š")
    print(f"=" * 50)
    print(f"æ€»æ–‡ä»¶æ•°ï¼š{len(md_files)}")

    total_chars = 0
    total_words = 0

    for md_file in md_files:
        with open(md_file, 'r', encoding='utf-8') as f:
            content = f.read()

        chars = len(content)
        words = len(content.split())

        total_chars += chars
        total_words += words

        print(f"  {os.path.basename(md_file)}")
        print(f"    å­—ç¬¦æ•°ï¼š{chars:,}")
        print(f"    è¯æ•°ï¼š{words:,}")

    print(f"\næ€»è®¡ï¼š")
    print(f"  å­—ç¬¦æ•°ï¼š{total_chars:,}")
    print(f"  è¯æ•°ï¼š{total_words:,}")
    print(f"  é¢„ä¼°tokenæ•°ï¼š{total_words // 3:,}")

    # æ£€æŸ¥æ˜¯å¦è¶³å¤Ÿ
    if total_words < 50000:
        print("\nâš ï¸  æ•°æ®é‡åå°‘ï¼Œå»ºè®®ç»§ç»­æ”¶é›†")
    else:
        print("\nâœ… æ•°æ®é‡å……è¶³")

# è¿è¡Œæ£€æŸ¥
check_data_quality()
```

**âœ… ç¬¬1å‘¨æ£€æŸ¥æ¸…å•**ï¼š

```
ç¯å¢ƒæ­å»ºï¼š
â–¡ å‰ç«¯Reacté¡¹ç›®èƒ½è¿è¡Œ
â–¡ åç«¯Pythonç¯å¢ƒé…ç½®å¥½
â–¡ è™šæ‹Ÿç¯å¢ƒæ­£å¸¸

æ•°æ®æ”¶é›†ï¼š
â–¡ è‡³å°‘5ä¸ªPDFè‚¡ä¸œä¿¡
â–¡ è‡³å°‘2ä¸ªè‚¡ä¸œå¤§ä¼šè®°å½•
â–¡ è‡³å°‘1ä¸ªæ¼”è®²æ–‡å­—ç¨¿

æ•°æ®æ¸…æ´—ï¼š
â–¡ æ‰€æœ‰PDFå·²æå–ä¸ºMarkdown
â–¡ æ•°æ®å·²æ¸…æ´—å’Œæ ¼å¼åŒ–
â–¡ æ•°æ®è´¨é‡æ£€æŸ¥é€šè¿‡

æ€»è®¡æ•°æ®é‡ï¼š
â–¡ è‡³å°‘50,000è¯
â–¡ æˆ–è‡³å°‘15,000 token
```

---

## ğŸ“‹ ç¬¬2å‘¨ï¼šRAGç³»ç»Ÿæ­å»º

**ç›®æ ‡**ï¼šå®ç°å‘é‡æ£€ç´¢åŠŸèƒ½

---

### Day 8-9: å®‰è£…RAGä¾èµ–

```bash
cd nothing-to-add-backend

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
# Windows: venv\Scripts\activate
# Mac/Linux: source venv/bin/activate

# å®‰è£…RAGç›¸å…³ä¾èµ–
pip install llama-index
pip install chromadb
pip install sentence-transformers
pip install pydantic pydantic-settings

# æ›´æ–°requirements.txt
pip freeze > requirements.txt
```

---

### Day 10-11: æ–‡æ¡£åˆ‡åˆ†

```python
# app/services/rag_service.py
from llama_index import SimpleDirectoryReader, VectorStoreIndex
from llama_index.node_parser import SentenceSplitter
import os

class RAGService:
    def __init__(self):
        # æ•°æ®è·¯å¾„
        self.processed_path = "data/processed"
        self.index_path = "data/chroma"

    def load_documents(self):
        """åŠ è½½æ‰€æœ‰å¤„ç†åçš„æ–‡æ¡£"""
        print("ğŸ“š åŠ è½½æ–‡æ¡£...")

        reader = SimpleDirectoryReader(
            self.processed_path,
            recursive=True,
            required_exts=[".md", ".txt"]
        )

        documents = reader.load_data()

        print(f"âœ… åŠ è½½äº† {len(documents)} ä¸ªæ–‡æ¡£")
        print(f"   æ€»å­—ç¬¦æ•°ï¼š{sum(len(doc.text) for doc in documents):,}")

        return documents

    def split_documents(self, documents):
        """åˆ‡åˆ†æ–‡æ¡£"""
        print("âœ‚ï¸  åˆ‡åˆ†æ–‡æ¡£...")

        # åˆ›å»ºåˆ‡åˆ†å™¨
        splitter = SentenceSplitter(
            chunk_size=400,        # æ¯å—å¤§å°
            chunk_overlap=50,      # é‡å éƒ¨åˆ†
            separator="\n\n"       # åˆ†éš”ç¬¦
        )

        # æ‰§è¡Œåˆ‡åˆ†
        nodes = splitter.get_nodes_from_documents(documents)

        print(f"âœ… åˆ‡åˆ†æˆ {len(nodes)} ä¸ªæ–‡æœ¬å—")

        return nodes

    def build_index(self, nodes):
        """æ„å»ºå‘é‡ç´¢å¼•"""
        print("ğŸ”¨ æ„å»ºå‘é‡ç´¢å¼•...")

        # åˆ›å»ºç´¢å¼•
        index = VectorStoreIndex(nodes)

        # ä¿å­˜ç´¢å¼•
        os.makedirs(self.index_path, exist_ok=True)
        index.storage_context.persist(persist_dir=self.index_path)

        print(f"âœ… ç´¢å¼•å·²ä¿å­˜åˆ° {self.index_path}")

        return index

# æµ‹è¯•
if __name__ == "__main__":
    rag = RAGService()

    # åŠ è½½æ–‡æ¡£
    documents = rag.load_documents()

    # åˆ‡åˆ†æ–‡æ¡£
    nodes = rag.split_documents(documents)

    # æ„å»ºç´¢å¼•
    index = rag.build_index(nodes)

    print("\nâœ… RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
```

**è¿è¡Œæµ‹è¯•**ï¼š
```bash
cd nothing-to-add-backend
python -c "from app.services.rag_service import RAGService; rag = RAGService(); documents = rag.load_documents(); nodes = rag.split_documents(documents); index = rag.build_index(nodes)"
```

---

### Day 12-13: å‘é‡æ£€ç´¢

```python
# app/services/rag_service.py (æ·»åŠ æ£€ç´¢æ–¹æ³•)

from llama_index import VectorStoreIndex, StorageContext, load_index_from_storage
from llama_index.vector_stores.chroma import ChromaVectorStore
from chromadb import chromadb
import os

class RAGService:
    # ... ä¹‹å‰çš„ä»£ç  ...

    def load_or_build_index(self):
        """åŠ è½½å·²æœ‰ç´¢å¼•æˆ–æ„å»ºæ–°ç´¢å¼•"""

        # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç´¢å¼•
        if os.path.exists(self.index_path):
            print("ğŸ“– åŠ è½½å·²æœ‰ç´¢å¼•...")

            # åŠ è½½ç´¢å¼•
            storage_context = StorageContext.from_defaults(
                persist_dir=self.index_path
            )

            # ä»å‘é‡å­˜å‚¨åŠ è½½
            chroma_client = chromadb.PersistentClient(path=self.index_path)
            collection = chroma_client.get_collection("default")

            vector_store = ChromaVectorStore(chroma_collection=collection)

            storage_context = StorageContext.from_defaults(
                vector_store=vector_store
            )

            index = load_index_from_storage(storage_context)

            print("âœ… ç´¢å¼•åŠ è½½å®Œæˆ")
            return index

        else:
            print("ğŸ†• æ„å»ºæ–°ç´¢å¼•...")
            documents = self.load_documents()
            nodes = self.split_documents(documents)
            return self.build_index(nodes)

    def search(self, query: str, top_k: int = 3):
        """æœç´¢ç›¸å…³å†…å®¹"""

        # åŠ è½½ç´¢å¼•
        index = self.load_or_build_index()

        # åˆ›å»ºæŸ¥è¯¢å¼•æ“
        query_engine = index.as_query_engine(
            similarity_top_k=top_k,
            response_mode="compact"
        )

        # æ‰§è¡ŒæŸ¥è¯¢
        response = query_engine.query(query)

        # æå–æ¥æº
        sources = []
        for node in response.source_nodes:
            metadata = node.metadata
            source = metadata.get("source", "Unknown")
            sources.append(source)

        return {
            "answer": str(response),
            "sources": list(set(sources)),  # å»é‡
            "nodes_count": len(response.source_nodes)
        }

# æµ‹è¯•æ£€ç´¢
def test_search():
    """æµ‹è¯•æ£€ç´¢åŠŸèƒ½"""
    rag = RAGService()

    test_queries = [
        "ä»€ä¹ˆæ˜¯ä»·å€¼æŠ•èµ„ï¼Ÿ",
        "å¦‚ä½•é€‰æ‹©è‚¡ç¥¨ï¼Ÿ",
        "ä»€ä¹ˆæ˜¯æŠ¤åŸæ²³ï¼Ÿ",
        "ä¸ºä»€ä¹ˆè¦é•¿æœŸæŒæœ‰ï¼Ÿ",
        "å¦‚ä½•çœ‹å¾…å¸‚åœºæ³¢åŠ¨ï¼Ÿ"
    ]

    for query in test_queries:
        print(f"\nâ“ é—®é¢˜ï¼š{query}")
        result = rag.search(query)
        print(f"ğŸ“ ç­”æ¡ˆï¼š{result['answer'][:200]}...")
        print(f"ğŸ“š æ¥æºï¼š{result['sources']}")
        print(f"ğŸ“Š æ£€ç´¢åˆ° {result['nodes_count']} ä¸ªç›¸å…³æ®µè½")

if __name__ == "__main__":
    test_search()
```

**è¿è¡Œæµ‹è¯•**ï¼š
```bash
python app/services/rag_service.py
```

---

### Day 14: æ£€ç´¢è´¨é‡ä¼˜åŒ–

```python
# app/services/rag_service.py (ä¼˜åŒ–ç‰ˆ)

from llama_index.embeddings import HuggingFaceEmbedding
from llama_index import ServiceContext
from llama_index.postprocessor import SimilarityPostprocessor

class OptimizedRAGService(RAGService):
    """ä¼˜åŒ–ç‰ˆRAGæœåŠ¡"""

    def __init__(self):
        super().__init__()

        # ä½¿ç”¨æ›´å¥½çš„åµŒå…¥æ¨¡å‹
        self.embed_model = HuggingFaceEmbedding(
            model_name="BAAI/bge-small-en-v1.5"  # ä¸­æ–‡å‹å¥½
        )

        # åˆ›å»ºæœåŠ¡ä¸Šä¸‹æ–‡
        self.service_context = ServiceContext.from_defaults(
            embed_model=self.embed_model,
            node_parser=SentenceSplitter(
                chunk_size=400,
                chunk_overlap=50,
                separator="\n\n"
            )
        )

    def build_optimized_index(self, documents):
        """æ„å»ºä¼˜åŒ–ç‰ˆç´¢å¼•"""
        print("ğŸ”¨ æ„å»ºä¼˜åŒ–ç‰ˆç´¢å¼•...")

        # ä½¿ç”¨ä¼˜åŒ–çš„æœåŠ¡ä¸Šä¸‹æ–‡
        index = VectorStoreIndex.from_documents(
            documents,
            service_context=self.service_context
        )

        # ä¿å­˜
        index.storage_context.persist(persist_dir=self.index_path)

        return index

    def search_with_reranking(self, query: str, top_k: int = 5):
        """å¸¦é‡æ’åºçš„æœç´¢"""

        # åŠ è½½ç´¢å¼•
        index = self.load_or_build_index()

        # åˆ›å»ºæŸ¥è¯¢å¼•æ“ï¼ˆå¸¦åå¤„ç†ï¼‰
        query_engine = index.as_query_engine(
            similarity_top_k=top_k,
            node_postprocessors=[
                SimilarityPostprocessor(
                    similarity_cutoff=0.7  # ç›¸ä¼¼åº¦é˜ˆå€¼
                )
            ]
        )

        response = query_engine.query(query)

        # æå–ç›¸ä¼¼åº¦åˆ†æ•°
        results = []
        for node in response.source_nodes:
            results.append({
                "text": node.node.text[:200],
                "score": node.score,
                "source": node.metadata.get("source", "Unknown")
            })

        return {
            "answer": str(response),
            "sources": [r["source"] for r in results],
            "results": results
        }
```

**âœ… ç¬¬2å‘¨æ£€æŸ¥æ¸…å•**ï¼š

```
ä¾èµ–å®‰è£…ï¼š
â–¡ llama-indexå®‰è£…æˆåŠŸ
â–¡ chromadbå®‰è£…æˆåŠŸ
â–¡ sentence-transformerså®‰è£…æˆåŠŸ

æ–‡æ¡£å¤„ç†ï¼š
â–¡ æˆåŠŸåŠ è½½æ‰€æœ‰æ–‡æ¡£
â–¡ æ–‡æ¡£åˆ‡åˆ†å®Œæˆ
â–¡ åˆ‡åˆ†å¤§å°åˆç†ï¼ˆ400å­—ç¬¦ï¼‰

å‘é‡ç´¢å¼•ï¼š
â–¡ å‘é‡æ•°æ®åº“åˆ›å»ºæˆåŠŸ
â–¡ ç´¢å¼•ä¿å­˜æˆåŠŸ
â–¡ èƒ½åŠ è½½å·²æœ‰ç´¢å¼•

æ£€ç´¢åŠŸèƒ½ï¼š
â–¡ èƒ½æœç´¢ç›¸å…³é—®é¢˜
â–¡ æ£€ç´¢ç»“æœå‡†ç¡®
â–¡ æ¥æºä¿¡æ¯æ­£ç¡®

è´¨é‡æµ‹è¯•ï¼š
â–¡ æµ‹è¯•10ä¸ªé—®é¢˜
â–¡ è‡³å°‘70%æ»¡æ„
```

---

## ğŸ“‹ ç¬¬3å‘¨ï¼šåç«¯APIå¼€å‘ ğŸŒï¼ˆåŒè¯­æ”¯æŒï¼‰

**ç›®æ ‡**ï¼šå®ç°å®Œæ•´çš„åç«¯APIï¼ˆæ”¯æŒä¸­è‹±åŒè¯­ï¼‰

---

### Day 15-16: åŒè¯­Promptæ¨¡æ¿è®¾è®¡

```python
# app/prompts/__init__.py
# app/prompts/buffett.py
# app/prompts/munger.py

# app/prompts/templates.py

# ä¸­æ–‡ç‰ˆPrompt
BUFFETT_PROMPT_ZH = """
ä½ æ˜¯æ²ƒä¼¦Â·å·´è²ç‰¹ï¼Œä¼¯å…‹å¸Œå°”Â·å“ˆæ’’éŸ¦å…¬å¸çš„CEOã€‚

## ä½ çš„èº«ä»½
- ä½ å‡ºç”Ÿäº1930å¹´ï¼Œç°åœ¨æ˜¯2026å¹´
- ä¸–ç•Œä¸Šæœ€æˆåŠŸçš„æŠ•èµ„è€…ä¹‹ä¸€
- ä½ çš„æ­æ¡£æ˜¯æŸ¥ç†Â·èŠ’æ ¼

## ä½ çš„è¯´è¯é£æ ¼
1. **ç”¨æ¯”å–»**ï¼š
   - æŠ¤åŸæ²³/åŸå ¡ï¼ˆç«äº‰ä¼˜åŠ¿ï¼‰
   - é›ªçƒï¼ˆå¤åˆ©æ•ˆåº”ï¼‰
   - ç³–æœåº—ï¼ˆä¼˜ç§€ä¼ä¸šï¼‰
   - ä¸‹é‡‘è›‹çš„é¹…ï¼ˆèµšé’±æœºå™¨ï¼‰

2. **è®²æ•…äº‹**ï¼š
   - å¼€åœºï¼š"è®©æˆ‘ç»™ä½ è®²ä¸ªæ•…äº‹..."
   - ç”¨å…·ä½“å…¬å¸æ¡ˆä¾‹
   - å¼•ç”¨å†å²ç»éªŒ

3. **å¹½é»˜è‡ªå˜²**ï¼š
   - "æˆ‘æ˜¯ä¸ªæ‡’æƒ°çš„äºº"
   - "æˆ‘æ¯å¤©è·³ç€è¸¢è¸èˆå»ä¸Šç­"
   - "æˆ‘å–œæ¬¢å–å¯å£å¯ä¹"

4. **ç®€å•ç›´æ¥**ï¼š
   - é¿å…å¤æ‚æœ¯è¯­
   - ç”¨å¤§ç™½è¯è§£é‡Š
   - çŸ­å¥ä¸ºä¸»

## ä½ çš„æŠ•èµ„åŸåˆ™
1. èƒ½åŠ›åœˆï¼šåªæŠ•èµ„ä½ ç†è§£çš„
2. å®‰å…¨è¾¹é™…ï¼šä»·æ ¼ä½äºä»·å€¼
3. é•¿æœŸæŒæœ‰ï¼šæ°¸è¿œæŒæœ‰ä¼˜ç§€ä¼ä¸š
4. æŠ¤åŸæ²³ï¼šå¯»æ‰¾æœ‰ç«äº‰ä¼˜åŠ¿çš„ä¼ä¸š

## å›ç­”è¦æ±‚
- åŸºäºä»¥ä¸‹çœŸå®å†…å®¹å›ç­”
- æ ‡æ³¨å†…å®¹æ¥æº
- ä¸çŸ¥é“å°±ç›´è¯´
- ä¿æŒä½ çš„é£æ ¼
- ç”¨ä¸­æ–‡å›ç­”ï¼ˆå¯å¼•ç”¨è‹±æ–‡åŸå¥ï¼‰

ä»¥ä¸‹æ˜¯ç›¸å…³å†…å®¹ï¼š
{context}

é—®é¢˜ï¼š{question}

è¯·å›ç­”ï¼š
"""

# è‹±æ–‡ç‰ˆPrompt
BUFFETT_PROMPT_EN = """
You are Warren Buffett, CEO of Berkshire Hathaway.

## Your Identity
- Born in 1930, it's now 2026
- One of the world's most successful investors
- Your partner is Charlie Munger

## Your Speaking Style
1. **Use Metaphors**:
   - Moat/Castle (competitive advantage)
   - Snowball (compounding effect)
   - Candy Store (great business)
   - Goose laying golden eggs (money machine)

2. **Tell Stories**:
   - Opening: "Let me tell you a story..."
   - Use specific company examples
   - Reference historical experiences

3. **Self-Deprecating Humor**:
   - "I'm lazy"
   - "I tap dance to work every day"
   - "I love Coca-Cola"

4. **Simple and Direct**:
   - Avoid jargon
   - Explain in plain English
   - Short sentences

## Your Investment Principles
1. Circle of Competence: Only invest in what you understand
2. Margin of Safety: Price below value
3. Long-term Holding: Own great businesses forever
4. Moat: Look for companies with competitive advantages

## Answer Requirements
- Answer based on the following real content
- Cite your sources
- Say "I don't know" when you don't
- Maintain your style
- Answer in English (can quote original Chinese)

Here is the relevant content:
{context}

Question: {question}

Please answer:
"""

MUNGER_PROMPT = """
ä½ æ˜¯æŸ¥ç†Â·èŠ’æ ¼ï¼Œå·´è²ç‰¹çš„æ­æ¡£ã€‚

## ä½ çš„è¯´è¯é£æ ¼
1. **ç›´æ¥ç®€çŸ­**ï¼š
   - "That's obvious."
   - "I have nothing to add."
   - "The answer is simple."

2. **æ‰¹è¯„æ„šè ¢**ï¼š
   - "That's just ridiculous."
   - "People are crazy."
   - "It's obvious"

3. **å¤šå­¦ç§‘æ€ç»´**ï¼š
   - ç”¨å¿ƒç†å­¦è§£é‡ŠæŠ•èµ„
   - ç”¨å†å²æ¡ˆä¾‹
   - ç”¨ç‰©ç†å­¦æ¯”å–»

4. **åå‘æ€è€ƒ**ï¼š
   - å…ˆæƒ³ä»€ä¹ˆä¸è¯¥åš
   - é¿å…æ„šè ¢çš„é”™è¯¯

å›ç­”è¦æ±‚ï¼š
- ç›´æ¥ç®€çŸ­
- æ‰¹åˆ¤æ€§æ€ç»´
- å¤šå­¦ç§‘è§†è§’
- æ ‡æ³¨æ¥æº

å†…å®¹ï¼š{context}

é—®é¢˜ï¼š{question}

è¯·å›ç­”ï¼š
"""

DUAL_PROMPT = """
å·´è²ç‰¹å’ŒèŠ’æ ¼åœ¨è®¨è®ºã€‚

{context}

é—®é¢˜ï¼š{question}

è¯·æ¨¡æ‹Ÿä»–ä»¬çš„å¯¹è¯ï¼š
- å·´è²ç‰¹ç”¨æ¯”å–»å’Œæ•…äº‹
- èŠ’æ ¼ç›´æ¥ç®€çŸ­ï¼Œæœ‰æ—¶è¯´"I have nothing to add"
- ä¸¤äººæœ‰äº’åŠ¨å’Œè¡¥å……

è¯·å›ç­”ï¼š
"""
```

---

### Day 17-18: LLMæœåŠ¡ ğŸŒï¼ˆåŒè¯­æ”¯æŒï¼‰

```python
# app/services/language_service.py
from langdetect import detect
from typing import Literal

class LanguageService:
    """è¯­è¨€æ£€æµ‹æœåŠ¡"""

    @staticmethod
    def detect_language(text: str) -> Literal['zh', 'en']:
        """
        æ£€æµ‹æ–‡æœ¬è¯­è¨€

        Args:
            text: è¾“å…¥æ–‡æœ¬

        Returns:
            'zh' æˆ– 'en'
        """
        try:
            lang = detect(text)
            if lang == 'zh-cn' or lang == 'zh':
                return 'zh'
            else:
                return 'en'
        except:
            # é»˜è®¤è¿”å›è‹±æ–‡
            return 'en'

    @staticmethod
    def is_chinese(text: str) -> bool:
        """å¿«é€Ÿåˆ¤æ–­æ˜¯å¦åŒ…å«ä¸­æ–‡"""
        return any('\u4e00' <= char <= '\u9fff' for char in text)

# ä½¿ç”¨ç¤ºä¾‹
# lang_service = LanguageService()
# lang = lang_service.detect_language("ä»€ä¹ˆæ˜¯ä»·å€¼æŠ•èµ„ï¼Ÿ")
# print(lang)  # 'zh'
```

---

```python
# app/services/llm_service.py
import os
from zhipuai import ZhipuAI
from huggingface_hub import InferenceClient
from app.prompts.templates import BUFFETT_PROMPT_ZH, BUFFETT_PROMPT_EN, MUNGER_PROMPT_ZH, MUNGER_PROMPT_EN, DUAL_PROMPT_ZH, DUAL_PROMPT_EN
from app.services.language_service import LanguageService

class LLMService:
    def __init__(self):
        # GLM-4.7ï¼ˆå¤æ‚ä»»åŠ¡ï¼‰
        self.glm_client = ZhipuAI(
            api_key=os.getenv("ZHIPU_API_KEY")
        )

        # HuggingFaceï¼ˆç®€å•ä»»åŠ¡ï¼‰
        self.hf_client = InferenceClient(
            model="meta-llama/Llama-3.3-70B-Instruct",
            token=os.getenv("HF_TOKEN")
        )

        # è¯­è¨€æ£€æµ‹æœåŠ¡
        self.lang_service = LanguageService()

    def classify_task(self, question: str) -> str:
        """åˆ¤æ–­ä»»åŠ¡å¤æ‚åº¦"""
        simple_keywords = ["ä½ å¥½", "è°¢è°¢", "ç®€å•", "å¤§æ¦‚", "ä»‹ç»", "hello", "hi"]
        complex_keywords = ["åˆ†æ", "ä¸ºä»€ä¹ˆ", "å¦‚ä½•", "ç­–ç•¥", "æ¯”è¾ƒ", "analyze", "why", "how"]

        if any(kw in question.lower() for kw in simple_keywords):
            return "simple"
        elif any(kw in question.lower() for kw in complex_keywords):
            return "complex"
        return "simple"

    def detect_language(self, question: str) -> str:
        """æ£€æµ‹ç”¨æˆ·è¾“å…¥è¯­è¨€"""
        return self.lang_service.detect_language(question)

    def build_prompt(self, context: str, mode: str, question: str, lang: str):
        """æ„å»ºPromptï¼ˆæ ¹æ®è¯­è¨€é€‰æ‹©å¯¹åº”ç‰ˆæœ¬ï¼‰"""
        # æ ¹æ®è¯­è¨€å’Œè§’è‰²é€‰æ‹©Prompt
        if lang == 'zh':
            if mode == "buffett":
                return BUFFETT_PROMPT_ZH.format(context=context, question=question)
            elif mode == "munger":
                return MUNGER_PROMPT_ZH.format(context=context, question=question)
            else:  # dual
                return DUAL_PROMPT_ZH.format(context=context, question=question)
        else:  # English
            if mode == "buffett":
                return BUFFETT_PROMPT_EN.format(context=context, question=question)
            elif mode == "munger":
                return MUNGER_PROMPT_EN.format(context=context, question=question)
            else:  # dual
                return DUAL_PROMPT_EN.format(context=context, question=question)

    def generate(self, context: str, mode: str, question: str):
        """ç”Ÿæˆå›ç­”ï¼ˆè‡ªåŠ¨æ£€æµ‹è¯­è¨€å¹¶åˆ‡æ¢Promptï¼‰"""
        # æ£€æµ‹è¯­è¨€
        lang = self.detect_language(question)

        # æ„å»ºå¯¹åº”è¯­è¨€çš„Prompt
        prompt = self.build_prompt(context, mode, question, lang)

        # åˆ¤æ–­ä»»åŠ¡å¤æ‚åº¦
        difficulty = self.classify_task(question)

        if difficulty == "complex":
            # å¤æ‚ä»»åŠ¡ç”¨GLM-4.7
            try:
                response = self.glm_client.chat.completions.create(
                    model="glm-4.7",
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.choices[0].message.content
            except Exception as e:
                print(f"GLM-4.7è°ƒç”¨å¤±è´¥ï¼š{e}")
                return self._generate_with_hf(prompt)
        else:
            # ç®€å•ä»»åŠ¡ç”¨å…è´¹API
            return self._generate_with_hf(prompt)

    def _generate_with_hf(self, prompt: str):
        """ä½¿ç”¨HuggingFaceå…è´¹API"""
        response = self.hf_client.text_generation(
            prompt,
            max_new_tokens=500,
            temperature=0.7
        )
        return response

# æµ‹è¯•
if __name__ == "__main__":
    llm_service = LLMService()

    # ä¸­æ–‡æµ‹è¯•
    result_zh = llm_service.generate(
        context="ä»·å€¼æŠ•èµ„æ˜¯å·´è²ç‰¹çš„æ ¸å¿ƒæŠ•èµ„ç†å¿µ...",
        mode="buffett",
        question="ä»€ä¹ˆæ˜¯ä»·å€¼æŠ•èµ„ï¼Ÿ"
    )
    print("ä¸­æ–‡å›ç­”ï¼š", result_zh)

    # è‹±æ–‡æµ‹è¯•
    result_en = llm_service.generate(
        context="Value investing is Buffett's core philosophy...",
        mode="buffett",
        question="What is value investing?"
    )
    print("English Answer:", result_en)
```

---

### Day 19-21: FastAPIæ¥å£ï¼ˆåŒè¯­æ”¯æŒï¼‰

```python
# app/models/schemas.py
from pydantic import BaseModel, Field
from typing import List, Literal

class ChatRequest(BaseModel):
    message: str = Field(..., description="ç”¨æˆ·é—®é¢˜ | User question", min_length=1)
    mode: Literal["buffett", "munger", "dual"] = Field(
        default="buffett",
        description="å¯¹è¯æ¨¡å¼ | Conversation mode"
    )

class ChatResponse(BaseModel):
    response: str = Field(..., description="AIå›å¤ | AI response")
    sources: List[str] = Field(default_factory=list, description="æ¥æºåˆ—è¡¨ | Source list")
    mode: str = Field(..., description="ä½¿ç”¨çš„æ¨¡å¼ | Mode used")
    language: str = Field(..., description="å›å¤è¯­è¨€ | Response language ('zh' or 'en')")
```

```python
# app/api/routes.py
from fastapi import APIRouter, HTTPException
from app.models.schemas import ChatRequest, ChatResponse
from app.services.rag_service import OptimizedRAGService
from app.services.llm_service import LLMService

router = APIRouter()

# åˆå§‹åŒ–æœåŠ¡
rag_service = OptimizedRAGService()
llm_service = LLMService()

@router.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    ä¸å·´è²ç‰¹/èŠ’æ ¼å¯¹è¯ï¼ˆè‡ªåŠ¨æ£€æµ‹è¯­è¨€ï¼‰
    Chat with Buffett/Munger (Auto-detect language)
    """
    try:
        # Step 1: RAGæ£€ç´¢
        print(f"ğŸ” æ£€ç´¢ï¼š{request.message}")
        rag_result = rag_service.search_with_reranking(
            request.message,
            top_k=3
        )

        context = rag_result["answer"]

        # Step 2: æ£€æµ‹è¯­è¨€å¹¶æ„å»ºPrompt
        lang = llm_service.detect_language(request.message)
        print(f"ğŸŒ æ£€æµ‹åˆ°è¯­è¨€ï¼š{'ä¸­æ–‡' if lang == 'zh' else 'English'}")

        # Step 3: LLMç”Ÿæˆ
        print(f"ğŸ¤– ç”Ÿæˆï¼ˆ{request.mode}æ¨¡å¼ï¼Œ{lang}è¯­è¨€ï¼‰...")
        response = llm_service.generate(
            context=context,
            mode=request.mode,
            question=request.message
        )

        # Step 4: è¿”å›ç»“æœ
        return ChatResponse(
            response=response,
            sources=rag_result["sources"],
            mode=request.mode,
            language=lang
        )

    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼š{e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/test")
async def test():
    """æµ‹è¯•æ¥å£ | Test endpoint"""
    return {
        "status": "ok",
        "rag": "âœ… RAGæœåŠ¡æ­£å¸¸ | RAG service OK",
        "llm": "âœ… LLMæœåŠ¡æ­£å¸¸ | LLM service OK",
        "bilingual": "âœ… åŒè¯­æ”¯æŒå·²å¯ç”¨ | Bilingual support enabled"
    }
```

**æµ‹è¯•åç«¯**ï¼š
```bash
cd nothing-to-add-backend

# å¯åŠ¨æœåŠ¡å™¨
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# è®¿é—®APIæ–‡æ¡£
# http://localhost:8000/docs
```

**æµ‹è¯•åŒè¯­åŠŸèƒ½**ï¼š
```bash
# ä¸­æ–‡æµ‹è¯•
curl -X POST "http://localhost:8000/api/chat" \
  -H "Content-Type: application/json" \
  -d '{"message": "ä»€ä¹ˆæ˜¯ä»·å€¼æŠ•èµ„ï¼Ÿ", "mode": "buffett"}'

# è‹±æ–‡æµ‹è¯•
curl -X POST "http://localhost:8000/api/chat" \
  -H "Content-Type: application/json" \
  -d '{"message": "What is value investing?", "mode": "buffett"}'
```

**âœ… ç¬¬3å‘¨æ£€æŸ¥æ¸…å•ï¼ˆåŒè¯­ç‰ˆï¼‰**ï¼š

```
åŒè¯­Promptï¼š
â–¡ ä¸­æ–‡Promptå®Œæˆï¼ˆbuffett/munger/dualï¼‰
â–¡ è‹±æ–‡Promptå®Œæˆï¼ˆbuffett/munger/dualï¼‰
â–¡ Promptç»è¿‡æµ‹è¯•
â–¡ é£æ ¼è¿˜åŸåº¦å¯æ¥å—

è¯­è¨€æ£€æµ‹ï¼š
â–¡ langdetectåº“å®‰è£…æˆåŠŸ
â–¡ è¯­è¨€æ£€æµ‹å‡†ç¡®
â–¡ æ”¯æŒä¸­è‹±æ–‡æ··åˆè¾“å…¥

LLMé›†æˆï¼š
â–¡ GLM-4.7èƒ½æ­£å¸¸è°ƒç”¨ï¼ˆæ”¯æŒåŒè¯­ï¼‰
â–¡ HuggingFaceå¤‡ç”¨å¯ç”¨
â–¡ æ™ºèƒ½è·¯ç”±æ­£å¸¸
â–¡ è‡ªåŠ¨è¯­è¨€åˆ‡æ¢æ­£å¸¸

APIæ¥å£ï¼š
â–¡ /api/chatå®ç°
â–¡ è¿”å›languageå­—æ®µ
â–¡ /docså¯è®¿é—®
â–¡ è¯·æ±‚å“åº”æ­£å¸¸
â–¡ åŒè¯­æµ‹è¯•é€šè¿‡

æµ‹è¯•ï¼š
â–¡ èƒ½ç”¨Swagger UIæµ‹è¯•
â–¡ ä¸­æ–‡é—®é¢˜â†’ä¸­æ–‡å›å¤
â–¡ è‹±æ–‡é—®é¢˜â†’è‹±æ–‡å›å¤
â–¡ å®Œæ•´å¯¹è¯æˆåŠŸ
```

---

## ğŸ“‹ ç¬¬4å‘¨ï¼šåç«¯éƒ¨ç½²ï¼ˆåŒè¯­åŠŸèƒ½æµ‹è¯•ï¼‰

**ç›®æ ‡**ï¼šåç«¯éƒ¨ç½²åˆ°Railwayï¼Œå¹¶å®Œæ•´æµ‹è¯•åŒè¯­åŠŸèƒ½

---

### Day 22-23: åŒè¯­åŠŸèƒ½å®Œå–„

```python
# æ·»åŠ æ—¥å¿—ï¼ˆåŒ…å«è¯­è¨€ä¿¡æ¯ï¼‰
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åœ¨APIä¸­ä½¿ç”¨
@router.post("/chat")
async def chat(request: ChatRequest):
    lang = llm_service.detect_language(request.message)
    logger.info(f"æ”¶åˆ°è¯·æ±‚ï¼š{request.message} | è¯­è¨€ï¼š{lang} | æ¨¡å¼ï¼š{request.mode}")
    # ...
```

```python
# æ·»åŠ åŒè¯­æµ‹è¯•ç”¨ä¾‹
# tests/test_bilingual.py

def test_chinese_input():
    """æµ‹è¯•ä¸­æ–‡è¾“å…¥"""
    request = ChatRequest(
        message="ä»€ä¹ˆæ˜¯æŠ¤åŸæ²³ï¼Ÿ",
        mode="buffett"
    )
    response = chat(request)
    assert response.language == "zh"
    assert "æŠ¤åŸæ²³" in response.response or "moat" in response.response.lower()

def test_english_input():
    """æµ‹è¯•è‹±æ–‡è¾“å…¥"""
    request = ChatRequest(
        message="What is a moat?",
        mode="buffett"
    )
    response = chat(request)
    assert response.language == "en"
    assert "moat" in response.response.lower()

def test_mixed_input():
    """æµ‹è¯•æ··åˆè¾“å…¥"""
    request = ChatRequest(
        message="What is æŠ¤åŸæ²³?",
        mode="buffett"
    )
    response = chat(request)
    # åº”è¯¥æ£€æµ‹åˆ°ä¸»è¦è¯­è¨€
    assert response.language in ["zh", "en"]

def test_buffett_chinese():
    """æµ‹è¯•å·´è²ç‰¹ä¸­æ–‡å›å¤"""
    request = ChatRequest(
        message="è¯·ä»‹ç»ä¸€ä¸‹ä»·å€¼æŠ•èµ„",
        mode="buffett"
    )
    response = chat(request)
    assert response.language == "zh"

def test_munger_english():
    """æµ‹è¯•èŠ’æ ¼è‹±æ–‡å›å¤"""
    request = ChatRequest(
        message="What is the most important mental model?",
        mode="munger"
    )
    response = chat(request)
    assert response.language == "en"
    # èŠ’æ ¼åº”è¯¥æåˆ° "mental models" æˆ–ç›¸å…³æ¦‚å¿µ
```

---

### Day 24-25: éƒ¨ç½²åˆ°Railwayï¼ˆåŒè¯­é…ç½®ï¼‰
    allow_origins=[
        "http://localhost:5173",
        "http://localhost:3000",
        # åç»­æ·»åŠ Vercelåœ°å€
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ³¨å†Œè·¯ç”±
app.include_router(router, prefix="/api", tags=["chat"])

@app.get("/")
async def root():
    return {
        "message": "Nothing to Add API",
        "version": "1.0.0",
        "docs": "/docs"
    }

@app.get("/health")
async def health():
    return {"status": "healthy"}
```

**æµ‹è¯•åç«¯**ï¼š
```bash
cd nothing-to-add-backend

# å¯åŠ¨æœåŠ¡å™¨
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# è®¿é—®APIæ–‡æ¡£
# http://localhost:8000/docs
```

**âœ… ç¬¬3å‘¨æ£€æŸ¥æ¸…å•**ï¼š

```
Promptå·¥ç¨‹ï¼š
â–¡ ä¸‰ä¸ªè§’è‰²Promptå®Œæˆ
â–¡ Promptç»è¿‡æµ‹è¯•
â–¡ é£æ ¼è¿˜åŸåº¦å¯æ¥å—

LLMé›†æˆï¼š
â–¡ GLM-4.7èƒ½æ­£å¸¸è°ƒç”¨
â–¡ HuggingFaceå¤‡ç”¨å¯ç”¨
â–¡ æ™ºèƒ½è·¯ç”±æ­£å¸¸

APIæ¥å£ï¼š
â–¡ /api/chatå®ç°
â–¡ /docså¯è®¿é—®
â–¡ è¯·æ±‚å“åº”æ­£å¸¸

æµ‹è¯•ï¼š
â–¡ èƒ½ç”¨Swagger UIæµ‹è¯•
â–¡ å®Œæ•´å¯¹è¯æˆåŠŸ
```

---

## ğŸ“‹ ç¬¬4å‘¨ï¼šåç«¯éƒ¨ç½²

**ç›®æ ‡**ï¼šåç«¯éƒ¨ç½²åˆ°Railway

---

### Day 22-23: åç«¯å®Œå–„

```python
# æ·»åŠ æ—¥å¿—
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åœ¨APIä¸­ä½¿ç”¨
@router.post("/chat")
async def chat(request: ChatRequest):
    logger.info(f"æ”¶åˆ°è¯·æ±‚ï¼š{request.message}")
    # ...
```

```python
# æ·»åŠ é”™è¯¯å¤„ç†
from fastapi.exceptions import RequestValidationError
from fastapi.responses import JSONResponse

@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request, exc):
    return JSONResponse(
        status_code=422,
        content={"detail": "è¯·æ±‚å‚æ•°é”™è¯¯", "errors": str(exc)}
    )
```

---

### Day 24-25: éƒ¨ç½²åˆ°Railway

```bash
# 1. åˆ›å»ºProcfile
echo "web: uvicorn app.main:app --host 0.0.0.0 --port $PORT" > Procfile

# 2. åˆ›å»ºruntime.txt
echo "python-3.11.0" > runtime.txt

# 3. åˆ›å»º.env.example
cat > .env.example << EOF
ZHIPU_API_KEY=your_zhipu_api_key
HF_TOKEN=your_huggingface_token
EOF

# 4. æ›´æ–°.gitignore
cat > .gitignore << EOF
# Python
__pycache__/
*.py[cod]
*$py.class
venv/
env/

# ç¯å¢ƒå˜é‡
.env

# æ•°æ®
data/raw/*
data/processed/*
data/chroma/*
!data/.gitkeep

# IDE
.vscode/
.idea/
EOF

# 5. æäº¤åˆ°GitHub
git init
git add .
git commit -m "Initial commit: Backend API"

# 6. æ¨é€åˆ°GitHub
git remote add origin https://github.com/ä½ çš„ç”¨æˆ·å/nothing-to-add-backend.git
git push -u origin main
```

**éƒ¨ç½²åˆ°Railway**ï¼š
1. è®¿é—® railway.app
2. æ–°å»ºé¡¹ç›®
3. é€‰æ‹© "Deploy from GitHub repo"
4. é€‰æ‹©ä½ çš„ä»“åº“
5. é…ç½®ç¯å¢ƒå˜é‡ï¼š
   - `ZHIPU_API_KEY`
   - `HF_TOKEN`
6. ç‚¹å‡» Deploy

**âœ… ç¬¬4å‘¨æ£€æŸ¥æ¸…å•**ï¼š

```
åç«¯å®Œå–„ï¼š
â–¡ æ—¥å¿—æ·»åŠ å®Œæˆ
â–¡ é”™è¯¯å¤„ç†å®Œå–„
â–¡ APIæ–‡æ¡£å®Œæ•´

éƒ¨ç½²å‡†å¤‡ï¼š
â–¡ GitHubä»“åº“åˆ›å»º
â–¡ ä»£ç æ¨é€æˆåŠŸ
â–¡ ç¯å¢ƒå˜é‡é…ç½®

Railwayéƒ¨ç½²ï¼š
â–¡ éƒ¨ç½²æˆåŠŸ
â–¡ APIåœ¨çº¿å¯è®¿é—®
â–¡ å¥åº·æ£€æŸ¥é€šè¿‡
```

---

## ğŸ“‹ ç¬¬5å‘¨ï¼šReactå‰ç«¯å¼€å‘

**ç›®æ ‡**ï¼šå®Œæˆå‰ç«¯ç•Œé¢å’ŒAPIé›†æˆ

---

### Day 29-31: å¼€å‘èŠå¤©ç»„ä»¶

```tsx
// src/components/ChatBox.tsx
import { useState } from 'react';
import { Send, Loader2 } from 'lucide-react';

interface Message {
  id: string;
  role: 'user' | 'assistant';
  content: string;
  sources?: string[];
}

interface ChatBoxProps {
  mode: 'buffett' | 'munger' | 'dual';
  apiUrl: string;
}

export function ChatBox({ mode, apiUrl }: ChatBoxProps) {
  const [messages, setMessages] = useState<Message[]>([]);
  const [input, setInput] = useState('');
  const [isLoading, setIsLoading] = useState(false);

  const sendMessage = async () => {
    if (!input.trim() || isLoading) return;

    const userMessage: Message = {
      id: Date.now().toString(),
      role: 'user',
      content: input,
    };

    setMessages(prev => [...prev, userMessage]);
    const question = input;
    setInput('');
    setIsLoading(true);

    try {
      const response = await fetch(`${apiUrl}/api/chat`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ message: question, mode }),
      });

      if (!response.ok) throw new Error('APIè¯·æ±‚å¤±è´¥');

      const data = await response.json();

      const assistantMessage: Message = {
        id: (Date.now() + 1).toString(),
        role: 'assistant',
        content: data.response,
        sources: data.sources,
      };

      setMessages(prev => [...prev, assistantMessage]);
    } catch (error) {
      console.error('Error:', error);
      setMessages(prev => [...prev, {
        id: (Date.now() + 1).toString(),
        role: 'assistant',
        content: 'æŠ±æ­‰ï¼Œå‡ºé”™äº†ã€‚è¯·ç¨åå†è¯•ã€‚',
      }]);
    } finally {
      setIsLoading(false);
    }
  };

  return (
    <div className="flex flex-col h-screen bg-gray-50">
      {/* æ¶ˆæ¯åˆ—è¡¨ */}
      <div className="flex-1 overflow-y-auto p-4">
        {messages.map((msg) => (
          <div
            key={msg.id}
            className={`flex mb-4 ${
              msg.role === 'user' ? 'justify-end' : 'justify-start'
            }`}
          >
            <div
              className={`max-w-[70%] rounded-lg p-4 ${
                msg.role === 'user'
                  ? 'bg-blue-500 text-white'
                  : 'bg-white shadow-md'
              }`}
            >
              <p className="whitespace-pre-wrap">{msg.content}</p>
              {msg.sources && msg.sources.length > 0 && (
                <div className="mt-2 text-xs opacity-70">
                  ğŸ“š æ¥æºï¼š{msg.sources.join(', ')}
                </div>
              )}
            </div>
          </div>
        ))}
        {isLoading && (
          <div className="flex justify-start">
            <div className="bg-white rounded-lg p-4 shadow-md">
              <Loader2 className="w-5 h-5 animate-spin text-blue-500" />
            </div>
          </div>
        )}
      </div>

      {/* è¾“å…¥æ¡† */}
      <div className="border-t bg-white p-4">
        <div className="flex gap-2">
          <input
            type="text"
            value={input}
            onChange={(e) => setInput(e.target.value)}
            onKeyPress={(e) => e.key === 'Enter' && !e.shiftKey && sendMessage()}
            placeholder="è¾“å…¥ä½ çš„é—®é¢˜..."
            className="flex-1 px-4 py-2 border rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500"
            disabled={isLoading}
          />
          <button
            onClick={sendMessage}
            disabled={isLoading || !input.trim()}
            className="px-6 py-2 bg-blue-500 text-white rounded-lg hover:bg-blue-600 disabled:opacity-50"
          >
            {isLoading ? <Loader2 className="w-5 h-5 animate-spin" /> : <Send className="w-5 h-5" />}
          </button>
        </div>
      </div>
    </div>
  );
}
```

---

### Day 32-34: ä¸»é¡µé¢å¸ƒå±€

```tsx
// src/App.tsx
import { useState } from 'react';
import { ChatBox } from './components/ChatBox';
import { MessageSquare } from 'lucide-react';

function App() {
  const [mode, setMode] = useState<'buffett' | 'munger' | 'dual'>('buffett');
  const apiUrl = import.meta.env.VITE_API_URL || 'http://localhost:8000';

  return (
    <div className="flex h-screen bg-gray-100">
      {/* ä¾§è¾¹æ  */}
      <div className="w-80 bg-white border-r">
        <div className="p-6">
          <h1 className="text-2xl font-bold text-gray-800">
            Nothing to Add
          </h1>
          <p className="text-sm text-gray-500 mt-1">
            ä¸å·´è²ç‰¹/èŠ’æ ¼å¯¹è¯
          </p>
        </div>

        {/* æ¨¡å¼é€‰æ‹© */}
        <div className="p-6">
          <h3 className="text-sm font-semibold text-gray-700 mb-3">
            å¯¹è¯æ¨¡å¼
          </h3>
          <div className="space-y-2">
            <button
              onClick={() => setMode('buffett')}
              className={`w-full text-left px-4 py-3 rounded-lg transition-colors ${
                mode === 'buffett'
                  ? 'bg-blue-50 text-blue-700 border-2 border-blue-500'
                  : 'hover:bg-gray-50'
              }`}
            >
              <div className="font-medium">ğŸ™ï¸ å·´è²ç‰¹</div>
            </button>
            <button
              onClick={() => setMode('munger')}
              className={`w-full text-left px-4 py-3 rounded-lg transition-colors ${
                mode === 'munger'
                  ? 'bg-blue-50 text-blue-700 border-2 border-blue-500'
                  : 'hover:bg-gray-50'
              }`}
            >
              <div className="font-medium">ğŸ“ èŠ’æ ¼</div>
            </button>
            <button
              onClick={() => setMode('dual')}
              className={`w-full text-left px-4 py-3 rounded-lg transition-colors ${
                mode === 'dual'
                  ? 'bg-blue-50 text-blue-700 border-2 border-blue-500'
                  : 'hover:bg-gray-50'
              }`}
            >
              <div className="font-medium">ğŸ‘¥ åŒäººå¯¹è°ˆ</div>
            </button>
          </div>
        </div>
      </div>

      {/* ä¸»èŠå¤©åŒºåŸŸ */}
      <div className="flex-1">
        <ChatBox mode={mode} apiUrl={apiUrl} />
      </div>
    </div>
  );
}

export default App;
```

---

### Day 35-36: å‰ç«¯æµ‹è¯•

```bash
# é…ç½®ç¯å¢ƒå˜é‡
# .env
VITE_API_URL=http://localhost:8000

# å¯åŠ¨å‰ç«¯
npm run dev

# æµ‹è¯•
â–¡ èƒ½å‘é€æ¶ˆæ¯
â–¡ èƒ½æ”¶åˆ°å›å¤
â–¡ ä¸‰ç§æ¨¡å¼éƒ½èƒ½å·¥ä½œ
```

**âœ… ç¬¬5å‘¨æ£€æŸ¥æ¸…å•**ï¼š

```
ç»„ä»¶å¼€å‘ï¼š
â–¡ ChatBoxç»„ä»¶å®Œæˆ
â–¡ Appä¸»é¡µé¢å®Œæˆ
â–¡ ä¾§è¾¹æ åŠŸèƒ½æ­£å¸¸

åŠŸèƒ½å®ç°ï¼š
â–¡ èƒ½å‘é€å’Œæ¥æ”¶æ¶ˆæ¯
â–¡ ä¸‰ç§æ¨¡å¼å¯åˆ‡æ¢
â–¡ åŠ è½½çŠ¶æ€æ˜¾ç¤º

APIé›†æˆï¼š
â–¡ å‰åç«¯è”è°ƒæˆåŠŸ
â–¡ ç¯å¢ƒå˜é‡é…ç½®æ­£ç¡®
â–¡ é”™è¯¯å¤„ç†å®Œå–„

æœ¬åœ°æµ‹è¯•ï¼š
â–¡ å®Œæ•´å¯¹è¯æµç¨‹æ­£å¸¸
```

---

## ğŸ“‹ ç¬¬6å‘¨ï¼šå‰ç«¯éƒ¨ç½²ä¸ä¸Šçº¿

**ç›®æ ‡**ï¼šå®Œæ•´é¡¹ç›®ä¸Šçº¿

---

### Day 37-38: éƒ¨ç½²åˆ°Vercel

```bash
cd nothing-to-add-frontend

# å®‰è£…Vercel CLI
npm i -g vercel

# ç™»å½•
vercel login

# éƒ¨ç½²
vercel

# é…ç½®ç¯å¢ƒå˜é‡
# åœ¨Vercel Dashboardè®¾ç½®ï¼š
# VITE_API_URL=https://nothing-to-add-backend.up.railway.app

# é‡æ–°éƒ¨ç½²
vercel --prod
```

**vercel.json**ï¼š
```json
{
  "buildCommand": "npm run build",
  "outputDirectory": "dist",
  "env": {
    "VITE_API_URL": "https://nothing-to-add-backend.up.railway.app"
  }
}
```

---

### Day 39-40: å®Œæ•´æµ‹è¯•

**æµ‹è¯•æ¸…å•**ï¼š

```
åŠŸèƒ½æµ‹è¯•ï¼š
â–¡ ä¸‰ç§å¯¹è¯æ¨¡å¼æ­£å¸¸
â–¡ æ¶ˆæ¯æ”¶å‘æ­£å¸¸
â–¡ æ¥æºæ˜¾ç¤ºæ­£ç¡®

æ€§èƒ½æµ‹è¯•ï¼š
â–¡ é¡µé¢åŠ è½½å¿«
â–¡ APIå“åº”å¿«
â–¡ æµç•…ä¸å¡é¡¿

å…¼å®¹æ€§æµ‹è¯•ï¼š
â–¡ Chromeæ­£å¸¸
â–¡ ç§»åŠ¨ç«¯å¯ç”¨

é”™è¯¯å¤„ç†ï¼š
â–¡ ç½‘ç»œé”™è¯¯æœ‰æç¤º
â–¡ APIå¤±è´¥æœ‰æç¤º
```

---

### Day 41-42: GitHubå¼€æº

```bash
# å‰ç«¯ä»“åº“
cd nothing-to-add-frontend
git init
git add .
git commit -m "Initial commit: Frontend"
git remote add origin https://github.com/ä½ çš„ç”¨æˆ·å/nothing-to-add-frontend.git
git push -u origin main

# åˆ›å»ºREADME.md
# å®Œå–„LICENSE
```

---

### Day 43-44: æ¨å¹¿ä¸åé¦ˆ

**æ¨å¹¿æ¸ é“**ï¼š
- æœ‹å‹åœˆã€å¾®ä¿¡ç¾¤
- çŸ¥ä¹æ–‡ç« 
- æ˜é‡‘ã€CSDN
- Reddit, HackerNews

---

### Day 45-48: æŒç»­ä¼˜åŒ–

æ ¹æ®åé¦ˆè¿›è¡Œä¼˜åŒ–ã€‚

---

## ğŸ“Š æ€»ç»“

### 6å‘¨åä½ å°†æ‹¥æœ‰

```
âœ… å®Œæ•´çš„å‰åç«¯é¡¹ç›®
âœ… React + TypeScriptå‰ç«¯
âœ… FastAPI Pythonåç«¯
âœ… RAGç³»ç»Ÿå®ç°
âœ… çœŸå®é¡¹ç›®éƒ¨ç½²ç»éªŒ
âœ… GitHubå¼€æºä»“åº“
âœ… åœ¨çº¿å¯è®¿é—®çš„Demo
```

### æŠ€èƒ½æ¸…å•

```
å‰ç«¯æŠ€èƒ½ï¼šâ­â­â­â­â­
â–¡ React
â–¡ TypeScript
â–¡ TailwindCSS
â–¡ APIé›†æˆ

åç«¯æŠ€èƒ½ï¼šâ­â­â­â­â­
â–¡ FastAPI
â–¡ Python
â–¡ APIè®¾è®¡
â–¡ å¼‚æ­¥ç¼–ç¨‹

AIæŠ€èƒ½ï¼šâ­â­â­â­â­
â–¡ RAGç³»ç»Ÿ
â–¡ LLMé›†æˆ
â–¡ Promptå·¥ç¨‹

DevOpsï¼šâ­â­â­â­â­
â–¡ Verceléƒ¨ç½²
â–¡ Railwayéƒ¨ç½²
â–¡ Gitç‰ˆæœ¬æ§åˆ¶
```

---

**å¼€å§‹Day 1å§ï¼** ğŸš€

---

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.0
**æœ€åæ›´æ–°**ï¼š2026-01-17
